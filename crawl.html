<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="A module to help you crawl policing websites and ingest them for later use with your LLM">

<title>police-risk-open-ai - Crawl</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="police-risk-open-ai - Crawl">
<meta property="og:description" content="A module to help you crawl policing websites and ingest them for later use with your LLM">
<meta property="og:site-name" content="police-risk-open-ai">
<meta name="twitter:title" content="police-risk-open-ai - Crawl">
<meta name="twitter:description" content="A module to help you crawl policing websites and ingest them for later use with your LLM">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">police-risk-open-ai</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Crawl</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">police-risk-open-ai</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./llm.html" class="sidebar-item-text sidebar-link">LLM</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./crawl.html" class="sidebar-item-text sidebar-link active">Crawl</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./variance_analysis.html" class="sidebar-item-text sidebar-link">Variance Analysis</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Analysis</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Analysis/chat_api.html" class="sidebar-item-text sidebar-link">chat_api.html</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Analysis/explainer.html" class="sidebar-item-text sidebar-link">An OpenAI Experiment - CopBot!</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Analysis/llm_risk_research.html" class="sidebar-item-text sidebar-link">Police versus Machine Assessed Risk</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Analysis/research_paper.html" class="sidebar-item-text sidebar-link">Large Language Models and Policing Risk Assessment for Missing People - Acccuracy and Bias</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#crawl" id="toc-crawl" class="nav-link active" data-scroll-target="#crawl">crawl</a></li>
  <li><a href="#get_domain_hyperlinks" id="toc-get_domain_hyperlinks" class="nav-link" data-scroll-target="#get_domain_hyperlinks">get_domain_hyperlinks</a></li>
  <li><a href="#get_hyperlinks" id="toc-get_hyperlinks" class="nav-link" data-scroll-target="#get_hyperlinks">get_hyperlinks</a></li>
  <li><a href="#hyperlinkparser" id="toc-hyperlinkparser" class="nav-link" data-scroll-target="#hyperlinkparser">HyperlinkParser</a></li>
  <li><a href="#crawl-1" id="toc-crawl-1" class="nav-link" data-scroll-target="#crawl-1">crawl</a></li>
  <li><a href="#get_domain_hyperlinks-1" id="toc-get_domain_hyperlinks-1" class="nav-link" data-scroll-target="#get_domain_hyperlinks-1">get_domain_hyperlinks</a></li>
  <li><a href="#get_hyperlinks-1" id="toc-get_hyperlinks-1" class="nav-link" data-scroll-target="#get_hyperlinks-1">get_hyperlinks</a></li>
  <li><a href="#hyperlinkparser-1" id="toc-hyperlinkparser-1" class="nav-link" data-scroll-target="#hyperlinkparser-1">HyperlinkParser</a></li>
  <li><a href="#clean_scrapped_data" id="toc-clean_scrapped_data" class="nav-link" data-scroll-target="#clean_scrapped_data">clean_scrapped_data</a></li>
  <li><a href="#remove_newlines" id="toc-remove_newlines" class="nav-link" data-scroll-target="#remove_newlines">remove_newlines</a></li>
  <li><a href="#split_into_many" id="toc-split_into_many" class="nav-link" data-scroll-target="#split_into_many">split_into_many</a></li>
  <li><a href="#produce_df_embeddings" id="toc-produce_df_embeddings" class="nav-link" data-scroll-target="#produce_df_embeddings">produce_df_embeddings</a></li>
  <li><a href="#bringing-it-together" id="toc-bringing-it-together" class="nav-link" data-scroll-target="#bringing-it-together">Bringing it Together</a>
  <ul class="collapse">
  <li><a href="#scrape_website" id="toc-scrape_website" class="nav-link" data-scroll-target="#scrape_website">scrape_website</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/AndreasThinks/police-risk-open-ai/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Crawl</h1>
</div>

<div>
  <div class="description">
    A module to help you crawl policing websites and ingest them for later use with your LLM
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>This notebook is intended to follow on from <code>police_risk_open_ai.core.llm</code>, and mostly replicates the opening stages of the <a href="https://platform.openai.com/docs/tutorials/web-qa-embeddings">OpenAI embedding tutorial</a>, though we make some code changes as we go.</p>
<p>We start by replicating their code that helps scrape pages using beautifulsoup.</p>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L220" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="crawl" class="level3">
<h3 class="anchored" data-anchor-id="crawl">crawl</h3>
<blockquote class="blockquote">
<pre><code> crawl (url)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L192" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="get_domain_hyperlinks" class="level3">
<h3 class="anchored" data-anchor-id="get_domain_hyperlinks">get_domain_hyperlinks</h3>
<blockquote class="blockquote">
<pre><code> get_domain_hyperlinks (local_domain, url)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L166" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="get_hyperlinks" class="level3">
<h3 class="anchored" data-anchor-id="get_hyperlinks">get_hyperlinks</h3>
<blockquote class="blockquote">
<pre><code> get_hyperlinks (url)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L151" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="hyperlinkparser" class="level3">
<h3 class="anchored" data-anchor-id="hyperlinkparser">HyperlinkParser</h3>
<blockquote class="blockquote">
<pre><code> HyperlinkParser ()</code></pre>
</blockquote>
<p>Find tags and other markup and call handler functions.</p>
<p>Usage: p = HTMLParser() p.feed(data) … p.close()</p>
<p>Start tags are handled by calling self.handle_starttag() or self.handle_startendtag(); end tags by self.handle_endtag(). The data between tags is passed from the parser to the derived class by calling self.handle_data() with the data as argument (the data may be split up in arbitrary chunks). If convert_charrefs is True the character references are converted automatically to the corresponding Unicode character (and self.handle_data() is no longer split in chunks), otherwise they are passed by calling self.handle_entityref() or self.handle_charref() with the string containing respectively the named or numeric reference as the argument.</p>
<p>Using the above function “out of the box” on the College of Policing APP website though doesn’t work as intended.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>domain <span class="op">=</span> <span class="st">"college.police.uk/app"</span> <span class="co"># &lt;- put your domain to be crawled</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>full_url <span class="op">=</span> <span class="st">"https://www.college.police.uk/app"</span> <span class="co"># &lt;- put your domain to be crawled with https or http</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>crawl(full_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>https://www.college.police.uk/app
HTTP Error 403: Forbidden</code></pre>
</div>
</div>
<p>This seems to be a cloudflare response to prevent crawlers, but we can get it around it by modifying out user heading. Rather than requesting the URL directly, we’ll inject in a header that looks like the Firefox browser.</p>
<p>That said, when you do scrape websites, make sure you do it ethically: consider how much you’re pulling in, what the audience is, and whether you might be impacting service for other users. Given the APP is public and in high use, I feel that’s okay here.</p>
<pre><code>
    request = urllib.request.Request(url, headers={'User-Agent':'Mozilla/5.0'})
    
    # Try to open the URL and read the HTML
    try:
        # Open the URL and read the HTML
        with urllib.request.urlopen(request) as response:</code></pre>
<p>I also add in a max length of the URL, because the College has some real weird stuff that is breaking my code.</p>
<pre><code>
        # Save text from the url to a &lt;url&gt;.txt file
        if len(url) &lt; 500:
            with open('text/'+local_domain+'/'+url[8:].replace("/", "_") + ".txt", "w", encoding="UTF-8") as f:
</code></pre>
<p>That code does succesfully manage to run through the entirety of the APP domain, so we bundle it up below.</p>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L220" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="crawl-1" class="level3">
<h3 class="anchored" data-anchor-id="crawl-1">crawl</h3>
<blockquote class="blockquote">
<pre><code> crawl (url)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L192" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="get_domain_hyperlinks-1" class="level3">
<h3 class="anchored" data-anchor-id="get_domain_hyperlinks-1">get_domain_hyperlinks</h3>
<blockquote class="blockquote">
<pre><code> get_domain_hyperlinks (local_domain, url)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L166" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="get_hyperlinks-1" class="level3">
<h3 class="anchored" data-anchor-id="get_hyperlinks-1">get_hyperlinks</h3>
<blockquote class="blockquote">
<pre><code> get_hyperlinks (url)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L151" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="hyperlinkparser-1" class="level3">
<h3 class="anchored" data-anchor-id="hyperlinkparser-1">HyperlinkParser</h3>
<blockquote class="blockquote">
<pre><code> HyperlinkParser ()</code></pre>
</blockquote>
<p>Find tags and other markup and call handler functions.</p>
<p>Usage: p = HTMLParser() p.feed(data) … p.close()</p>
<p>Start tags are handled by calling self.handle_starttag() or self.handle_startendtag(); end tags by self.handle_endtag(). The data between tags is passed from the parser to the derived class by calling self.handle_data() with the data as argument (the data may be split up in arbitrary chunks). If convert_charrefs is True the character references are converted automatically to the corresponding Unicode character (and self.handle_data() is no longer split in chunks), otherwise they are passed by calling self.handle_entityref() or self.handle_charref() with the string containing respectively the named or numeric reference as the argument.</p>
<p>Let’s test it out on my website. As you can see, loops through each hyperlink, and crawls it in turn, saving each as a local file.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Regex pattern to match a URL</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>HTTP_URL_PATTERN <span class="op">=</span> <span class="vs">r'^http[s]*://.+'</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>domain <span class="op">=</span> <span class="st">"andreasthinks.me"</span> <span class="co"># &lt;- put your domain to be crawled</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>full_url <span class="op">=</span> <span class="st">"https://andreasthinks.me/"</span> <span class="co"># &lt;- put your domain to be crawled with https or http</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>crawl(full_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>https://andreasthinks.me/
https://andreasthinks.me/./recent_work.html
https://andreasthinks.me/./index.xml</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/andreasthinksmint/python_env/cop-bot/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features="xml"` into the BeautifulSoup constructor.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>https://andreasthinks.me/./posts/lockdown_effect/index.html
https://andreasthinks.me/../../index.xml
HTTP Error 400: Bad Request
https://andreasthinks.me/../../recent_work.html
HTTP Error 400: Bad Request
https://andreasthinks.me/../../about.html
HTTP Error 400: Bad Request
https://andreasthinks.me/../../index.html
HTTP Error 400: Bad Request
https://andreasthinks.me/./posts/migrated_to_quarto/index.html
https://andreasthinks.me/./posts/burglary_attendance/index.html</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>KeyboardInterrupt: </code></pre>
</div>
</div>
<p>With our API now scraped, we can move on to cleaning irrelevant data, and outputing something we can work with.</p>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L281" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="clean_scrapped_data" class="level3">
<h3 class="anchored" data-anchor-id="clean_scrapped_data">clean_scrapped_data</h3>
<blockquote class="blockquote">
<pre><code> clean_scrapped_data (scrape_directory,
                      output_file='processed/scraped.csv')</code></pre>
</blockquote>
<p>takes a folder containing all the file from your scrapped data, cleans it all, saves as a CSV and returns the dataframe</p>
<p>if given None as output_file, dataframe returned but not saved</p>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L274" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="remove_newlines" class="level3">
<h3 class="anchored" data-anchor-id="remove_newlines">remove_newlines</h3>
<blockquote class="blockquote">
<pre><code> remove_newlines (serie)</code></pre>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>cleaned_df <span class="op">=</span> clean_scrapped_data(<span class="st">"text/www.college.police.uk"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>cleaned_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_197341/3678221184.py:5: FutureWarning: The default value of regex will change from True to False in a future version.
  serie = serie.str.replace('\\n', ' ')</code></pre>
</div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>fname</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>.police.uk app</td>
      <td>.police.uk app.           APP (authorised prof...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>.police.uk</td>
      <td>.police.uk.            Working together | Coll...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>.police.uk about</td>
      <td>.police.uk about.           About us | College...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>.police.uk about concordats</td>
      <td>.police.uk about concordats.           Concord...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>.police.uk about publication scheme</td>
      <td>.police.uk about publication scheme.          ...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4441</th>
      <td>.police.uk cdn cgi l email protection#cb8fedaa...</td>
      <td>.police.uk cdn cgi l email protection#cb8fedaa...</td>
    </tr>
    <tr>
      <th>4442</th>
      <td>.police.uk cdn cgi l email protection#d3b7f5b2...</td>
      <td>.police.uk cdn cgi l email protection#d3b7f5b2...</td>
    </tr>
    <tr>
      <th>4443</th>
      <td>.police.uk cdn cgi l email protection#206f6446...</td>
      <td>.police.uk cdn cgi l email protection#206f6446...</td>
    </tr>
    <tr>
      <th>4444</th>
      <td>.police.uk cdn cgi l email protection#97f4f8f9...</td>
      <td>.police.uk cdn cgi l email protection#97f4f8f9...</td>
    </tr>
    <tr>
      <th>4445</th>
      <td>.police.uk cdn cgi l email protection#02706771...</td>
      <td>.police.uk cdn cgi l email protection#02706771...</td>
    </tr>
  </tbody>
</table>
<p>4446 rows × 2 columns</p>
</div>
</div>
</div>
<p>So there you have it! An entire website, scraped and cleaned, ready to be ingested into our AI model.</p>
<p>Before we can begin analysis, we need to split our text into <code>tokens</code>, recognisable chunks of text-data our model will recognise.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"processed/scraped.csv"</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> [<span class="st">'title'</span>, <span class="st">'text'</span>]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before we can begin analysis, we need to split our text into <code>tokens</code>, recognisable chunks of text-data our model will recognise.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize the text and save the number of tokens to a new column</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'n_tokens'</span>] <span class="op">=</span> df.text.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(tokenizer.encode(x)))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the distribution of the number of tokens per row using a histogram</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>df.n_tokens.hist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can’t handle that many tokens, so we build a function to break them into chunks.</p>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L315" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="split_into_many" class="level3">
<h3 class="anchored" data-anchor-id="split_into_many">split_into_many</h3>
<blockquote class="blockquote">
<pre><code> split_into_many (text, max_tokens=500)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L353" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="produce_df_embeddings" class="level3">
<h3 class="anchored" data-anchor-id="produce_df_embeddings">produce_df_embeddings</h3>
<blockquote class="blockquote">
<pre><code> produce_df_embeddings (df, chunk_size=100)</code></pre>
</blockquote>
<p>produces embeddings from the open AI api in chunks</p>
</section>
<section id="bringing-it-together" class="level2">
<h2 class="anchored" data-anchor-id="bringing-it-together">Bringing it Together</h2>
<p>Let’s now make a master function that scrapes a website, cleans it, tokenises it, converts to embeddings, and saves.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crawl(url, export_dir<span class="op">=</span><span class="st">'scrape_export'</span>):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parse the URL and get the domain</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(export_dir <span class="op">+</span> <span class="st">"/"</span>):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>            os.mkdir(export_dir <span class="op">+</span> <span class="st">"/"</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    export_directory_loc <span class="op">=</span> export_dir <span class="op">+</span> <span class="st">"/"</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    local_domain <span class="op">=</span> urlparse(url).netloc</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a queue to store the URLs to crawl</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    queue <span class="op">=</span> deque([url])</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a set to store the URLs that have already been seen (no duplicates)</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    seen <span class="op">=</span> <span class="bu">set</span>([url])</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a directory to store the text files</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(export_directory_loc <span class="op">+</span> <span class="st">"text/"</span>):</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>            os.mkdir(export_directory_loc <span class="op">+</span> <span class="st">"text/"</span>)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(export_directory_loc <span class="op">+</span> <span class="st">"text/"</span><span class="op">+</span>local_domain<span class="op">+</span><span class="st">"/"</span>):</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>            os.mkdir(export_directory_loc <span class="op">+</span> <span class="st">"text/"</span> <span class="op">+</span> local_domain <span class="op">+</span> <span class="st">"/"</span>)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a directory to store the csv files</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(export_directory_loc <span class="op">+</span> <span class="st">"processed"</span>):</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>            os.mkdir(export_directory_loc <span class="op">+</span> <span class="st">"processed"</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># While the queue is not empty, continue crawling</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> queue:</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the next URL from the queue</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        url <span class="op">=</span> queue.pop()</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(url) <span class="co"># for debugging and to see the progress</span></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save text from the url to a &lt;url&gt;.txt file</span></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(export_directory_loc <span class="op">+</span> <span class="st">'text/'</span><span class="op">+</span>local_domain<span class="op">+</span><span class="st">'/'</span><span class="op">+</span>url[<span class="dv">8</span>:].replace(<span class="st">"/"</span>, <span class="st">"_"</span>) <span class="op">+</span> <span class="st">".txt"</span>, <span class="st">"w"</span>, encoding<span class="op">=</span><span class="st">"UTF-8"</span>) <span class="im">as</span> f:</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the text from the URL using BeautifulSoup</span></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>            soup <span class="op">=</span> BeautifulSoup(requests.get(url).text, <span class="st">"html.parser"</span>)</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the text but remove the tags</span></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>            text <span class="op">=</span> soup.get_text()</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the crawler gets to a page that requires JavaScript, it will stop the crawl</span></span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (<span class="st">"You need to enable JavaScript to run this app."</span> <span class="kw">in</span> text):</span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"Unable to parse page "</span> <span class="op">+</span> url <span class="op">+</span> <span class="st">" due to JavaScript being required"</span>)</span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Otherwise, write the text to the file in the text directory</span></span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>            f.write(text)</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the hyperlinks from the URL and add them to the queue</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> link <span class="kw">in</span> get_domain_hyperlinks(local_domain, url):</span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> link <span class="kw">not</span> <span class="kw">in</span> seen:</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>                queue.append(link)</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>                seen.add(link)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>domain <span class="op">=</span> <span class="st">"andreasthinks.me"</span> <span class="co"># &lt;- put your domain to be crawled</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>full_url <span class="op">=</span> <span class="st">"https://andreasthinks.me/"</span> <span class="co"># &lt;- put your domain to be crawled with https or http</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>crawl(full_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>https://andreasthinks.me/
https://andreasthinks.me/./recent_work.html
https://andreasthinks.me/./index.xml</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/andreasthinksmint/python_env/cop-bot/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features="xml"` into the BeautifulSoup constructor.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>https://andreasthinks.me/./posts/lockdown_effect/index.html
https://andreasthinks.me/../../index.xml</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>KeyboardInterrupt: </code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AndreasThinks/police-risk-open-ai/blob/main/police_risk_open_ai/crawl.py#L386" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="scrape_website" class="level3">
<h3 class="anchored" data-anchor-id="scrape_website">scrape_website</h3>
<blockquote class="blockquote">
<pre><code> scrape_website (url, export_dir='scrape_export')</code></pre>
</blockquote>
<p>Takes a url, scrapes and saves to the folder</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>